import logging
from aiogram import Router, F, Bot
from aiogram.types import Message, ContentType, CallbackQuery, FSInputFile
from aiogram.filters import CommandStart, Command
import os
from bot.services.storage import YandexStorageService
from bot.services.speechkit import SpeechKitService

from bot.services.llm import YandexGPTService

router = Router()
logger = logging.getLogger(__name__)

from bot.services.database import DatabaseService

# Initialize services (Global for router)
db_service = DatabaseService()

@router.message(CommandStart())
async def command_start_handler(message: Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è —Ä–∞—Å–ø–æ–∑–Ω–∞—é –µ–≥–æ —á–µ—Ä–µ–∑ Yandex SpeechKit (+ –ê–Ω–∞–ª–∏–∑ YandexGPT).")

@router.message(Command("id"))
async def command_id_handler(message: Message):
    await message.reply(f"üÜî ID —ç—Ç–æ–≥–æ —á–∞—Ç–∞: `{message.chat.id}`\n(–°–∫–æ–ø–∏—Ä—É–π—Ç–µ —ç—Ç–æ –≤ .env –∫–∞–∫ TARGET_CHAT_ID)")

@router.callback_query(F.data.startswith("take_task_"))
async def callback_take_task(callback: CallbackQuery):
    task_id = callback.data.split("_")[-1]
    username = callback.from_user.username or callback.from_user.first_name
    
    # Get current text to append status
    current_text = callback.message.text
    # Or caption if it's a document/file
    if not current_text:
        current_text = callback.message.caption or ""
        
    new_text = f"{current_text}\n\nüî® **–í–∑—è–ª –≤ —Ä–∞–±–æ—Ç—É:** @{username}"
    
    try:
        if callback.message.content_type == ContentType.TEXT:
            await callback.message.edit_text(new_text, reply_markup=None, parse_mode="Markdown")
        elif callback.message.content_type == ContentType.DOCUMENT:
             await callback.message.edit_caption(caption=new_text, reply_markup=None, parse_mode="Markdown")
             
        await callback.answer("–í—ã –≤–∑—è–ª–∏ –∑–∞–¥–∞—á—É!")
    except Exception as e:
        logger.error(f"Error editing message: {e}")
        await callback.answer("–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞", show_alert=True)

@router.message(Command("export"))
async def command_export_handler(message: Message):
    import pandas as pd
    
    msg = await message.reply("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç—á–µ—Ç...")
    
    try:
        tasks = await db_service.get_all_tasks()
        
        if not tasks:
            await msg.edit_text("üìÇ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞.")
            return

        # Prepare Data for Excel
        df = pd.DataFrame(tasks)
        
        if df.empty:
             await msg.edit_text("üìÇ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞.")
             return

        # Rename columns if they exist
        # REQUIRED 7 COLUMNS:
        # 1 —Å—Ç–æ–ª–±–µ—Ü ‚Äì –Ω–æ–º–µ—Ä –¥–∏–∞–ª–æ–≥–∞
        # 2 —Å—Ç–æ–ª–±–µ—Ü ‚Äì –Ω–æ–º–µ—Ä –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ (–∏–º—è —Ñ–∞–π–ª–∞)
        # 3 —Å—Ç–æ–ª–±–µ—Ü ‚Äì —Ç–µ–∫—Å—Ç –∑–≤–æ–Ω–∫–∞ (result_text)
        # 4 —Å—Ç–æ–ª–±–µ—Ü ‚Äì —Ñ—Ä–∞–∑–∞ –∂–∏—Ç–µ–ª—è (resident_phrase)
        # 5 —Å—Ç–æ–ª–±–µ—Ü ‚Äì —Ñ—Ä–∞–∑–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ (–∏–∑ –º–∞—Ä–∫–µ—Ä–æ–≤ –∏–ª–∏ –ø—É—Å—Ç–∞—è? User says "—Ñ—Ä–∞–∑–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞". We only store 'refusal_marker' which contains phrases and type)
        # 6 —Å—Ç–æ–ª–±–µ—Ü ‚Äì –º–∞—Ä–∫–µ—Ä –æ—Ç–∫–∞–∑–∞ (Same as above? Or split? User list in 5 and 6 columns suggests separate. But we have 'refusal_marker' stored as combined string.)
        # Let's map 'refusal_marker' to both for now or just put it in one and leave other empty if we can't split easily.
        # Actually, let's just map as requested:
        
        column_map = {
            'id': '–ù–æ–º–µ—Ä –¥–∏–∞–ª–æ–≥–∞',
            'file_name': '–ù–æ–º–µ—Ä –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞', 
            'result_text': '–¢–µ–∫—Å—Ç –∑–≤–æ–Ω–∫–∞',
            'resident_phrase': '–§—Ä–∞–∑–∞ –∂–∏—Ç–µ–ª—è',
            'refusal_marker': '–ú–∞—Ä–∫–µ—Ä –æ—Ç–∫–∞–∑–∞', # This contains "Type (Phrase)"
            'accident_duration': '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≤–∞—Ä–∏–∏',
        }
        
        # We need a 5th column "–§—Ä–∞–∑–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞". Since our `refusal_marker` field is "Type ('Phrase')", 
        # we can try to duplicate it or just provide the full marker string in both if fuzzy.
        # Ideally we would split it, but for now let's reuse.
        # Wait, column 5 is "Phrase Operator", column 6 is "Marker".
        # Let's add a calculated column for "Operator Phrase" based on "Refusal Marker" string.
        
        if 'refusal_marker' in df.columns:
            # Simple extraction regex if format is "Type ('Phrase')"
            # If multiple markers, it's semicolon separated.
            # Let's just copy the column for now to ensure column exists.
            df['–§—Ä–∞–∑–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞'] = df['refusal_marker'] 
        else:
             df['–§—Ä–∞–∑–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞'] = ""

        ordered_columns = [
            '–ù–æ–º–µ—Ä –¥–∏–∞–ª–æ–≥–∞', 
            '–ù–æ–º–µ—Ä –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞', 
            '–¢–µ–∫—Å—Ç –∑–≤–æ–Ω–∫–∞', 
            '–§—Ä–∞–∑–∞ –∂–∏—Ç–µ–ª—è', 
            '–§—Ä–∞–∑–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞', 
            '–ú–∞—Ä–∫–µ—Ä –æ—Ç–∫–∞–∑–∞', 
            '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≤–∞—Ä–∏–∏'
        ]
        
        # Filter only existing columns (using mapped names)
        # First rename what we can
        rename_map = {k:v for k,v in column_map.items() if k in df.columns}
        export_df = df.rename(columns=rename_map)
        
        # Ensure all ordered columns exist (add empty if missing)
        for col in ordered_columns:
            if col not in export_df.columns:
                export_df[col] = ""
                
        # Select final order
        export_df = export_df[ordered_columns]
        
        filename = f"export_{message.from_user.id}.xlsx"
        export_df.to_excel(filename, index=False)
        
        input_file = FSInputFile(filename)
        await message.reply_document(input_file, caption="üìä –í—ã–≥—Ä—É–∑–∫–∞ —Ç–∞–±–ª–∏—Ü—ã (7 —Å—Ç–æ–ª–±—Ü–æ–≤)")
        
        os.remove(filename)
        await msg.delete()
        
    except Exception as e:
        logger.error(f"Export error: {e}", exc_info=True)
        await msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–≥—Ä—É–∑–∫–∏: {e}")

@router.message(Command("stats"))
async def command_stats_handler(message: Message):
    """
    Generates a statistical report based on V3.1 requirements.
    1. Counts for 4 specific categories.
    2. Street clustering (streets with complaints from >= 2 distinct houses).
    """
    status_msg = await message.reply("üìä –°—á–∏—Ç–∞—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É...")
    
    try:
        tasks = await db_service.get_all_tasks()
        
        # 1. Category Counters
        cat_refusal = 0
        cat_no_brigade = 0
        cat_long = 0
        cat_redirect = 0
        
        # 2. Street Clustering Data
        # Structure: { "street_name": { "house_1", "house_2" } }
        street_map = {}
        
        relevant_count = 0
        
        for t in tasks:
            # Only consider relevant tasks that passed the hard filter
            if t.get('is_relevant_hard'):
                relevant_count += 1
                
                # Categories
                if t.get('category_refusal_works'): cat_refusal += 1
                if t.get('category_no_brigade'): cat_no_brigade += 1
                if t.get('category_long_duration'): cat_long += 1
                if t.get('category_redirect'): cat_redirect += 1
                
                # Clustering
                street = t.get('cleaned_street')
                house = t.get('cleaned_house')
                
                if street and house:
                    # Normalize strict comparison
                    s_norm = street.strip().lower()
                    h_norm = house.strip().lower()
                    
                    if s_norm not in street_map:
                        street_map[s_norm] = {'name': street, 'houses': set()}
                    
                    street_map[s_norm]['houses'].add(h_norm)

        # Build Report
        report = (
            f"üìà **–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –°–≤–æ–¥–∫–∞ (V3.1)**\n"
            f"–í—Å–µ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {relevant_count}\n\n"
            f"üîç **–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –ø—Ä–æ–±–ª–µ–º:**\n"
            f"1. üö´ –û—Ç–∫–∞–∑ –≤ —Å—Ä–æ–∫–∞—Ö: **{cat_refusal}**\n"
            f"2. üöí –ù–µ—Ç –±—Ä–∏–≥–∞–¥—ã: **{cat_no_brigade}**\n"
            f"3. ‚è≥ –î–ª–∏—Ç–µ–ª—å–Ω–∞—è (>24—á): **{cat_long}**\n"
            f"4. ‚Ü™Ô∏è –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: **{cat_redirect}**\n\n"
            f"üèò **–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —É–ª–∏—Ü—ã (2+ –¥–æ–º–∞):**\n"
        )
        
        # Filter streets with >= 2 distinct houses
        problem_streets = []
        for s_key, data in street_map.items():
            if len(data['houses']) >= 2:
                # Format: "—É–ª. –õ–µ–Ω–∏–Ω–∞ (–¥. 5, 7)"
                houses_str = ", ".join(sorted(list(data['houses'])))
                problem_streets.append(f"- {data['name']} (–¥. {houses_str}) ‚Äî {len(data['houses'])} –∑–∞—è–≤(–æ–∫)")
        
        if problem_streets:
            report += "\n".join(problem_streets)
        else:
            report += "‚úÖ –ú–∞—Å—Å–æ–≤—ã—Ö –∞–≤–∞—Ä–∏–π (—Ä–∞–∑–Ω—ã–µ –¥–æ–º–∞ –Ω–∞ –æ–¥–Ω–æ–π —É–ª–∏—Ü–µ) –Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ."
            
        await status_msg.edit_text(report, parse_mode="Markdown")
        
    except Exception as e:
        logger.error(f"Stats error: {e}", exc_info=True)
        await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

@router.message(Command("clean"))
async def command_clean_handler(message: Message):
    """
    Cleans up storage manually (S3 and Local).
    """
    logger.info(f"Received /clean command from user {message.from_user.id}")
    status_msg = await message.reply("üßπ –ù–∞—á–∏–Ω–∞—é –æ—á–∏—Å—Ç–∫—É —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...")
    
    try:
        # 1. Clean S3
        # Clean S3 (FULL WIPE)
        # We assume the storage service instance from global var or create new
        storage = YandexStorageService()
        
        # Clean Everything
        count_s3 = await storage.cleanup_all()
        
        # 2. Clean Local
        import glob
        local_files = glob.glob("temp_*") + glob.glob("transcript_*") + glob.glob("export_*")
        count_local = 0
        for f in local_files:
            try:
                os.remove(f)
                count_local += 1
            except:
                pass
                
        report = (
            f"‚úÖ **–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!**\n\n"
            f"‚òÅÔ∏è **–Ø–Ω–¥–µ–∫—Å S3:**\n"
            f"- –£–¥–∞–ª–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {count_s3}\n\n"
            f"üñ• **–õ–æ–∫–∞–ª—å–Ω—ã–π –¥–∏—Å–∫:**\n"
            f"- –£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {count_local}"
        )
        await status_msg.edit_text(report, parse_mode="Markdown")
        
    except Exception as e:
        logger.error(f"Cleanup error: {e}", exc_info=True)
        await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}")

@router.message(F.content_type.in_([ContentType.VOICE, ContentType.AUDIO, ContentType.DOCUMENT]))
async def voice_message_handler(message: Message, bot: Bot):
    user_id = message.from_user.id
    
    # Determine file_id and file_name based on content type
    if message.content_type == ContentType.VOICE:
        file_id = message.voice.file_id
        original_name = "voice.ogg" 
    elif message.content_type == ContentType.AUDIO:
        file_id = message.audio.file_id
        original_name = message.audio.file_name or "audio.mp3"
    elif message.content_type == ContentType.DOCUMENT:
        mime = str(message.document.mime_type).lower()
        fname = message.document.file_name.lower() if message.document.file_name else ""
        
        is_zip = mime == 'application/zip' or fname.endswith('.zip')
        is_rar = 'rar' in mime or fname.endswith('.rar')
        
        if is_zip or is_rar:
             # Archive
             pass # Accepted
        elif not mime.startswith('audio/'):
            await message.reply("üìÇ –≠—Ç–æ –Ω–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –∏ –Ω–µ –∞—Ä—Ö–∏–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ –∏–ª–∏ .zip/.rar –∞—Ä—Ö–∏–≤.")
            return
            
        file_id = message.document.file_id
        original_name = message.document.file_name or "document"
        
        # Determine effective file type
        effective_content_type = message.content_type
        if is_zip:
            effective_content_type = 'application/zip'
        elif is_rar:
            effective_content_type = 'application/x-rar-compressed'
    else:
        return

    # Add to Queue
    try:
        task_id = await db_service.add_task(
            user_id=user_id, 
            file_type=effective_content_type, 
            source_path=file_id, 
            file_name=original_name
        )
        
        await message.reply(f"üì• **–ü—Ä–∏–Ω—è—Ç–æ –≤ –æ–±—Ä–∞–±–æ—Ç–∫—É!**\n–ù–æ–º–µ—Ä –∑–∞–¥–∞—á–∏: `#{task_id}`\n\n–Ø —É–≤–µ–¥–æ–º–ª—é –≤–∞—Å, –∫–æ–≥–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤.")
        
    except Exception as e:
        logger.error(f"Failed to queue task: {e}", exc_info=True)
        await message.reply("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –≤ –æ—á–µ—Ä–µ–¥—å.")
